from .speaker.voice_recorder import VoiceRecorder
from .speaker.audio_to_text import AudioToText
from .speaker.wake_word_activation import WakeWordActivation
from .speaker.speaker_verification import SpeakerVerifier
from .ai.gemini_ai import GeminiAI
from .ai.permission_manager import PermissionManager
# from tts import tts_speak  # ê¸°ì¡´ TTS ëª¨ë“ˆì€ ë‚˜ì¤‘ì— ì„¤ì •
from playsound import playsound
from .config import THRESHOLD
import json
import requests
import os
from dotenv import load_dotenv
from typing import Dict

BASE_DIR = os.path.dirname(__file__)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

def main():
    # Initialize Gemini AI
    gemini = GeminiAI(api_key=os.getenv("GEMINI_API_KEY"))
    
    # Initialize permission manager
    permission_manager = PermissionManager()
    
    # Initialize AudioToText and VoiceRecorder objects once (important!)
    audio_processor = AudioToText()
    voice_recorder = VoiceRecorder()
    
    with open("src/smarterspeaker/users.JSON", "r") as file:
        users = json.load(file)
    
    while True:
        # 1. Voice recording
        recorded_file = voice_recorder.record()
        wake = WakeWordActivation(audio_processor, "Hello")
        
        # 2. Wake word verification
        if wake.is_activated("voice_sample.wav"):
            # 3. Speaker authentication
            user = SpeakerVerifier().identify_speaker(recorded_file, users, THRESHOLD)
            
            if user is not None:
                print(f"âœ… Authentication successful: {user}")
                # Play welcome sound
                success_sound = os.path.join(BASE_DIR, "voice_samples", user, "voices", "valid.wav")
                print("[DEBUG] Playing success sound:", success_sound)
                playsound(success_sound)
                playsound(f"voice_samples/{user}/voices/valid.wav")
                
                # Add personalized greeting with TTS
                greeting = f"Hello {user}, what can I help you with today?"
                print(f"ğŸ¤– {greeting}")
                tts_speak(greeting)
                
                # Enter command mode
                print(f"\nğŸ¯ {user}'s AI Assistant Mode")
                command_mode(user, voice_recorder, audio_processor, gemini, permission_manager)
                break  # Exit loop when command mode ends
                    
            else:
                print("âŒ Authentication failed!")
                playsound("src/smarterspeaker/voices/invalid.mp3")

def command_mode(user: str, voice_recorder, audio_processor, gemini, permission_manager):
    """Continuous command processing mode"""
    print("ğŸ“‹ Command examples: 'What's the weather?', 'Play music', 'Turn on lights', etc.")
    
    while True:
        try:
            print("\n" + "="*50)
            print("ğŸ’¬ Please speak your command")
            print("âŒ¨ï¸  Press Enter to start recording")
            print("ğŸšª Type 'q' + Enter to logout")
            print("="*50)
            
            user_input = input(">>> ").strip().lower()
            if user_input == 'q':
                print(f"ğŸ‘‹ {user} logged out.")
                break
            
            # Record command
            print("ğŸ¤ Please speak your command...")
            command_file = voice_recorder.record("command.wav", duration=5)
            
             # Convert speech to text
                        # Convert speech to text
            # Convert speech to text
            try:
                print("ğŸ”„ Converting speech to text...")
                command_text = audio_processor.transcribe(command_file)
                print(f"ğŸ“ Recognized command: {command_text}")
            except Exception as e:
                print(f"âŒ Speech conversion error: {e}")
                continue

            try:
                print("ğŸŒ Sending recognized text to movie search API...")
                resp = requests.post(
                    "http://127.0.0.1:8000/voice-search",
                    json={"text": command_text, "user": user},  # ğŸ”¹ í™”ì ì´ë¦„ë„ ê°™ì´ ì „ì†¡
                    timeout=1.5,
                )

                if resp.ok:
                    api_data = resp.json()
                    allowed = api_data.get("allowed", True)
                    reason = api_data.get("reason")

                    # ğŸ”’ ë‚˜ì´ ì œí•œ ê±¸ë¦° ê²½ìš°: ìŠ¤í”¼ì»¤ê°€ reason ì½ì–´ì£¼ê³ , ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ë„˜ì–´ê°
                    if not allowed:
                        print("ğŸš« Movie blocked by age restriction:", reason)
                        if reason:
                            tts_speak(reason)
                        else:
                            tts_speak("Sorry, this movie is restricted due to your age.")
                        # ì´ ëª…ë ¹ì€ ì—¬ê¸°ì„œ ë. ì•„ë˜ Gemini ì²˜ë¦¬ë¡œ ë‚´ë ¤ê°€ì§€ ì•ŠìŒ.
                        continue
                else:
                    print(f"âš ï¸ Movie API returned status {resp.status_code}")
            except Exception as e:
                print(f"âš ï¸ Movie API connection error: {e}")

                continue
            
            if not command_text.strip():
                print("âŒ Command not recognized. Please try again.")
                continue
            
            # Process with Gemini AI
            try:
                print("ğŸ¤– Processing with Gemini AI...")
                result = gemini.process_command(user, command_text)
            except Exception as e:
                print(f"âŒ AI processing error: {e}")
                continue
            
            # Permission check
            if result['action']:
                allowed, permission_message = permission_manager.check_permission(
                    user, result['intent'], result['entities'], command_text
                )
                
                if not allowed:
                    print(f"ğŸš« Permission denied: {permission_message}")
                    print("ğŸ”Š Playing audio response...")
                    tts_speak(permission_message)
                    continue
            
            # Display AI response
            print(f"ğŸ¤– AI Response: {result['response']}")
            print(f"ğŸ” Intent: {result['intent']}")
            print(f"ğŸ“Š Entities: {result['entities']}")
            
            # TTS response
            print("ğŸ”Š Playing audio response...")
            tts_speak(result['response'])
            
            # Execute action
            if result['action']:
                execute_action(result['action'])
            
        except KeyboardInterrupt:
            print(f"\nğŸ‘‹ {user} logged out.")
            break

import requests

BACKEND_URL = "http://127.0.0.1:8000"   # FastAPI ì„œë²„ ì£¼ì†Œ

def execute_action(action: Dict):
    """Execute AI generated action"""

    # Step 1: action í˜•ì‹ í™•ì¸
    if action.get("type") != "device_control":
        print("â— Unknown action type:", action)
        return

    device_id = action.get("device_id")
    operation = action.get("operation")   # "on" / "off" / "toggle"

    if device_id is None:
        print("â— device_id not provided in action")
        return

    # Step 2: í˜„ì¬ ê¸°ê¸° ìƒíƒœ ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        devices = requests.get(f"{BACKEND_URL}/devices").json()
    except Exception as e:
        print("â— Could not load devices:", e)
        return

    dev_map = {d["id"]: d for d in devices}

    if device_id not in dev_map:
        print("â— Device not found:", device_id)
        return

    current = dev_map[device_id]
    current_status = current["status"]

    # Step 3: ë‹¤ìŒ ìƒíƒœ ê²°ì •
    if operation == "toggle":
        if current["type"] == "door":
            next_status = "unlocked" if current_status == "locked" else "locked"
        else:
            next_status = "off" if current_status == "on" else "on"
    else:
        next_status = operation   # on/off/locked/unlocked

    # Step 4: ì„œë²„ì— ìƒíƒœ ì—…ë°ì´íŠ¸ ìš”ì²­
    try:
        res = requests.post(
            f"{BACKEND_URL}/devices/{device_id}",
            json={"status": next_status},
            timeout=3,
        )
        if res.status_code == 200:
            print(f"âœ… Device updated: id={device_id}, status={next_status}")
        else:
            print("â— Update failed:", res.text)
    except Exception as e:
        print("â— Error updating device:", e)

def execute_action(action: Dict):
    """Execute AI generated action"""
    action_type = action.get('type')
    
    if action_type == 'device_control':
        print(f"ğŸ  Device control: {action}")
        # TODO: Add actual IoT device control code
        # Example: smart_home_api.control_device(action['device'], action['parameters'])
        
    elif action_type == 'weather_query':
        print(f"â˜ï¸ Weather query: {action}")
        # TODO: Add weather API call code
        # Example: weather_api.get_weather(action['time'])
        
    elif action_type == 'music_play':
        print(f"ğŸµ Music playback: {action}")
        # TODO: Add music streaming API call
        # Example: music_api.play(action['query'])

def tts_speak(text: str):
    """Convert text to speech and play"""
    try:
        import pyttsx3
        engine = pyttsx3.init()
        
        # Force English voice selection
        voices = engine.getProperty('voices')
        
        # Select best English voice
        english_voice_found = False
        for voice in voices:
            if any(lang in voice.id.lower() for lang in ['en_us', 'en-us', 'english', 'alex', 'daniel', 'karen', 'samantha']):
                engine.setProperty('voice', voice.id)
                english_voice_found = True
                print(f"ğŸ¤ Using English voice: {voice.name}")
                break
        
        if not english_voice_found and voices:
            # Use first voice (usually English on most systems)
            engine.setProperty('voice', voices[0].id)
            print(f"ğŸ¤ Using default voice: {voices[0].name}")
        
        # Voice settings
        engine.setProperty('rate', 160)     # Speaking rate
        engine.setProperty('volume', 0.9)   # Volume
        
        # Voice output
        print(f"ğŸ¤ TTS (ğŸ‡ºğŸ‡¸ EN): '{text}'")
        engine.say(text)
        engine.runAndWait()
        
    except Exception as e:
        print(f"âŒ TTS error: {e}")
        print("ğŸ’¬ Text response: " + text)

def start_ai_session_with_components(user: str, audio_processor, voice_recorder):
    """Start AI session with pre-initialized components"""
    print(f"[DEBUG] Starting AI session with existing components for user: {user}")
    
    try:
        # Initialize Gemini AI
        print("[DEBUG] Initializing Gemini AI...")
        gemini = GeminiAI(api_key=os.getenv("GEMINI_API_KEY"))
        print("[DEBUG] Gemini AI initialized")
        
        # Initialize permission manager
        print("[DEBUG] Initializing permission manager...")
        permission_manager = PermissionManager()
        print("[DEBUG] Permission manager initialized")
        
        # Add personalized greeting with TTS
        greeting = f"Hello {user}, what can I help you with today?"
        print(f"ğŸ¤– {greeting}")
        tts_speak(greeting)
        
        # Enter command mode
        print(f"\nğŸ¯ {user}'s AI Assistant Mode")
        command_mode(user, voice_recorder, audio_processor, gemini, permission_manager)
    except Exception as e:
        print(f"[ERROR] Exception in start_ai_session_with_components: {e}")
        import traceback
        traceback.print_exc()

def start_ai_session_with_existing_components(user: str, audio_processor=None, voice_recorder=None):
    """Start AI session for authenticated user with existing components"""
    print(f"[DEBUG] start_ai_session_with_existing_components called for user: {user}")
    
    try:
        # Initialize Gemini AI
        print("[DEBUG] Initializing Gemini AI...")
        api_key = os.getenv("GEMINI_API_KEY")
        print(f"[DEBUG] API Key exists: {api_key is not None}")
        gemini = GeminiAI(api_key=api_key)
        print("[DEBUG] Gemini AI initialized")
        
        # Initialize permission manager
        print("[DEBUG] Initializing permission manager...")
        permission_manager = PermissionManager()
        print("[DEBUG] Permission manager initialized")
        
        # Use existing audio components or create new ones
        if audio_processor is None or voice_recorder is None:
            print("[DEBUG] Creating new audio components...")
            audio_processor = AudioToText()
            voice_recorder = VoiceRecorder()
            print("[DEBUG] Audio components created")
        else:
            print("[DEBUG] Using existing audio components")
        
        # Add personalized greeting with TTS
        greeting = f"Hello {user}, what can I help you with today?"
        print(f"ğŸ¤– {greeting}")
        print("[DEBUG] About to call tts_speak...")
        tts_speak(greeting)
        print("[DEBUG] TTS completed")
        
        # Enter command mode
        print(f"\nğŸ¯ {user}'s AI Assistant Mode")
        print("[DEBUG] Entering command_mode...")
        command_mode(user, voice_recorder, audio_processor, gemini, permission_manager)
    except Exception as e:
        print(f"[ERROR] Exception in start_ai_session: {e}")
        import traceback
        traceback.print_exc()

def start_ai_session(user: str):
    """Start AI session for authenticated user"""
    print(f"[DEBUG] start_ai_session called for user: {user}")
    
    try:
        # Initialize Gemini AI
        print("[DEBUG] Initializing Gemini AI...")
        api_key = os.getenv("GEMINI_API_KEY")
        print(f"[DEBUG] API Key exists: {api_key is not None}")
        gemini = GeminiAI(api_key=api_key)
        print("[DEBUG] Gemini AI initialized")
        
        # Initialize permission manager
        print("[DEBUG] Initializing permission manager...")
        permission_manager = PermissionManager()
        print("[DEBUG] Permission manager initialized")
        
        # Initialize VoiceRecorder only (AudioToText causes issues)
        print("[DEBUG] Initializing voice recorder...")
        voice_recorder = VoiceRecorder()
        print("[DEBUG] Voice recorder initialized")
        
        # Skip AudioToText initialization for now
        audio_processor = None
        print("[DEBUG] Skipping AudioToText initialization to avoid conflicts")
        
        # Add personalized greeting with TTS
        greeting = f"Hello {user}, what can I help you with today?"
        print(f"ğŸ¤– {greeting}")
        print("[DEBUG] About to call tts_speak...")
        tts_speak(greeting)
        print("[DEBUG] TTS completed")
        
        # Enter command mode
        print(f"\nğŸ¯ {user}'s AI Assistant Mode")
        print("[DEBUG] Entering command_mode...")
        command_mode(user, voice_recorder, audio_processor, gemini, permission_manager)
    except Exception as e:
        print(f"[ERROR] Exception in start_ai_session: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()