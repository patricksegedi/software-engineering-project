from .speaker.voice_recorder import VoiceRecorder
from .smarthome_client import control_device
from .speaker.audio_to_text import AudioToText
from .speaker.wake_word_activation import WakeWordActivation
from .speaker.speaker_verification import SpeakerVerifier
from .ai.gemini_ai import GeminiAI
from .ai.permission_manager import PermissionManager
# from tts import tts_speak  # ê¸°ì¡´ TTS ëª¨ë“ˆì€ ë‚˜ì¤‘ì— ì„¤ì •
from playsound import playsound
from .config import THRESHOLD
import json
import requests
import os
from dotenv import load_dotenv
from typing import Dict

BASE_DIR = os.path.dirname(__file__)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


# =========================================================
#  ìŠ¤ë§ˆíŠ¸í™ˆ ì œì–´ ê´€ë ¨ í—¬í¼ í•¨ìˆ˜ë“¤
# =========================================================

def handle_device_command(zone: str, device_type: str, action: str) -> None:
    """
    zone / device_type / action ê°’ì„ ë°›ì•„ì„œ
    ì‹¤ì œë¡œ FastAPI ì„œë²„ì— /device-control ìš”ì²­ì„ ë³´ë‚´ëŠ” í•¨ìˆ˜.
    """
    print(f"[SPEAKER] control request: zone={zone}, type={device_type}, action={action}")
    result = control_device(zone, device_type, action)
    print(f"[SPEAKER] control result: {result}")


def try_handle_smart_home(text: str) -> bool:
    """
    STTë¡œ ë‚˜ì˜¨ ì „ì²´ ë¬¸ì¥ì„ ë°›ì•„ì„œ
    - zone
    - device_type
    - action
    ì„ ê°„ë‹¨í•œ ê·œì¹™ìœ¼ë¡œ ì¶”ì¶œí•œ ë’¤,
    ì„¸ ê°œê°€ ë‹¤ ê²°ì •ë˜ë©´ handle_device_commandë¥¼ í˜¸ì¶œí•œë‹¤.

    ì²˜ë¦¬í–ˆìœ¼ë©´ True, ì•„ë‹ˆë©´ False ë°˜í™˜.
    """

    t = text.strip()
    t_lower = t.lower()

    zone = None
    device_type = None
    action = None

    # ===== 1) ì¡´ ì¶”ì¶œ =====
    if "ê±°ì‹¤" in t or "living room" in t_lower:
        zone = "Living"
    elif "ì¹¨ì‹¤" in t or "ì•ˆë°©" in t or "bedroom" in t_lower:
        zone = "Bedroom"

    # ===== 2) ê¸°ê¸° íƒ€ì… ì¶”ì¶œ =====
    if "ë¶ˆ" in t or "ì „ë“±" in t or "light" in t_lower:
        device_type = "light"
    elif "ì—ì–´ì»¨" in t or "aircon" in t_lower or "ac" in t_lower:
        device_type = "ac"
    elif "í‹°ë¹„" in t or "tv" in t_lower:
        device_type = "tv"
    elif "ë¬¸" in t or "door" in t_lower:
        device_type = "door"

    # ===== 3) ì•¡ì…˜ ì¶”ì¶œ =====
    if "ì¼œ" in t or "on" in t_lower:
        action = "on"
    elif "êº¼" in t or "off" in t_lower:
        action = "off"
    elif "ì ê°€" in t or "lock" in t_lower:
        action = "lock"
    elif "ì—´ì–´" in t or "unlock" in t_lower:
        action = "unlock"

    # ì„¸ ê°œ ë‹¤ ëª» ì°¾ìœ¼ë©´ ìŠ¤ë§ˆíŠ¸í™ˆ ëª…ë ¹ì´ ì•„ë‹Œ ê±¸ë¡œ ê°„ì£¼
    if not (zone and device_type and action):
        return False

    # ===== 4) ì‹¤ì œ ì œì–´ í˜¸ì¶œ =====
    print(f"[SMART_HOME] zone={zone}, type={device_type}, action={action}")
    handle_device_command(zone, device_type, action)

    return True


# =========================================================
#  ë©”ì¸ / ì»¤ë§¨ë“œ ëª¨ë“œ
# =========================================================

def main():
    # Initialize Gemini AI
    gemini = GeminiAI(api_key=os.getenv("GEMINI_API_KEY"))
    
    # Initialize permission manager
    permission_manager = PermissionManager()
    
    # Initialize AudioToText and VoiceRecorder objects once (important!)
    audio_processor = AudioToText()
    voice_recorder = VoiceRecorder()
    
    with open("src/smarterspeaker/users.JSON", "r") as file:
        users = json.load(file)
    
    while True:
        # 1. Voice recording
        recorded_file = voice_recorder.record()
        wake = WakeWordActivation(audio_processor, "Hello")
        
        # 2. Wake word verification
        if wake.is_activated("voice_sample.wav"):
            # 3. Speaker authentication
            user = SpeakerVerifier().identify_speaker(recorded_file, users, THRESHOLD)
            
            if user is not None:
                print(f"âœ… Authentication successful: {user}")
                # Play welcome sound
                
                # Add personalized greeting with TTS
                greeting = f"Hello {user}, what can I help you with today?"
                print(f"ğŸ¤– {greeting}")
                tts_speak(greeting)
                
                # Enter command mode
                print(f"\nğŸ¯ {user}'s AI Assistant Mode")
                command_mode(user, voice_recorder, audio_processor, gemini, permission_manager)
                break  # Exit loop when command mode ends
                    
            else:
                print("âŒ Authentication failed!")
                playsound("src/smarterspeaker/voices/invalid.mp3")


def command_mode(user: str, voice_recorder, audio_processor, gemini, permission_manager):
    """Continuous command processing mode"""
    print("ğŸ“‹ Command examples: 'What's the weather?', 'Play music', 'Turn on lights', etc.")
    
    while True:
        try:
            print("\n" + "="*50)
            print("ğŸ’¬ Please speak your command")
            print("âŒ¨ï¸  Press Enter to start recording")
            print("ğŸšª Type 'q' + Enter to logout")
            print("="*50)
            
            user_input = input(">>> ").strip().lower()
            if user_input == 'q':
                print(f"ğŸ‘‹ {user} logged out.")
                break
            
            # Record command
            print("ğŸ¤ Please speak your command...")
            command_file = voice_recorder.record("command.wav", duration=5)
            
            # Convert speech to text
            try:
                print("ğŸ”„ Converting speech to text...")
                command_text = audio_processor.transcribe(command_file)
                print(f"ğŸ“ Recognized command: {command_text}")
            except Exception as e:
                print(f"âŒ Speech conversion error: {e}")
                continue

            # ğŸ”¹ 1ì°¨ë¡œ ìŠ¤ë§ˆíŠ¸í™ˆ ëª…ë ¹ì¸ì§€ ë¨¼ì € ì²´í¬
            if try_handle_smart_home(command_text):
                # ìŠ¤ë§ˆíŠ¸í™ˆ ì œì–´ë¥¼ ì´ë¯¸ ìˆ˜í–‰í–ˆìœ¼ë¯€ë¡œ,
                # ì˜í™” ê²€ìƒ‰ / Gemini ì²˜ë¦¬ë¡œ ë‚´ë ¤ê°€ì§€ ì•Šê³  ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ
                continue

            # ğŸ”¹ ê¸°ì¡´ ì˜í™” ê²€ìƒ‰ API í˜¸ì¶œ
            try:
                print("ğŸŒ Sending recognized text to movie search API...")
                resp = requests.post(
                    "http://127.0.0.1:8000/voice-search",
                    json={"text": command_text, "user": user},  # ğŸ”¹ í™”ì ì´ë¦„ë„ ê°™ì´ ì „ì†¡
                    timeout=1.5,
                )

                if resp.ok:
                    api_data = resp.json()
                    allowed = api_data.get("allowed", True)
                    reason = api_data.get("reason")

                    # ğŸ”’ ë‚˜ì´ ì œí•œ ê±¸ë¦° ê²½ìš°: ìŠ¤í”¼ì»¤ê°€ reason ì½ì–´ì£¼ê³ , ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ë„˜ì–´ê°
                    if not allowed:
                        print("ğŸš« Movie blocked by age restriction:", reason)
                        if reason:
                            tts_speak(reason)
                        else:
                            tts_speak("Sorry, this movie is restricted due to your age.")
                        # ì´ ëª…ë ¹ì€ ì—¬ê¸°ì„œ ë. ì•„ë˜ Gemini ì²˜ë¦¬ë¡œ ë‚´ë ¤ê°€ì§€ ì•ŠìŒ.
                        continue
                else:
                    print(f"âš ï¸ Movie API returned status {resp.status_code}")
            except Exception as e:
                print(f"âš ï¸ Movie API connection error: {e}")
                continue
            
            if not command_text.strip():
                print("âŒ Command not recognized. Please try again.")
                continue
            
            # Process with Gemini AI
            try:
                print("ğŸ¤– Processing with Gemini AI...")
                result = gemini.process_command(user, command_text)
            except Exception as e:
                print(f"âŒ AI processing error: {e}")
                continue
            
            # Permission check
            if result['action']:
                allowed, permission_message = permission_manager.check_permission(
                    user, result['intent'], result['entities'], command_text
                )
                
                if not allowed:
                    print(f"ğŸš« Permission denied: {permission_message}")
                    print("ğŸ”Š Playing audio response...")
                    tts_speak(permission_message)
                    continue
            
            # Display AI response
            print(f"ğŸ¤– AI Response: {result['response']}")
            print(f"ğŸ” Intent: {result['intent']}")
            print(f"ğŸ“Š Entities: {result['entities']}")
            
            # TTS response
            print("ğŸ”Š Playing audio response...")
            tts_speak(result['response'])
            
            # Execute action (ê¸°ì¡´ device_id ë°©ì‹)
            if result['action']:
                execute_action(result['action'])
            
        except KeyboardInterrupt:
            print(f"\nğŸ‘‹ {user} logged out.")
            break


# =========================================================
#  ê¸°ì¡´ execute_action / TTS / ì„¸ì…˜ ê´€ë ¨ í•¨ìˆ˜ë“¤
# =========================================================

BACKEND_URL = "http://127.0.0.1:8000"   # FastAPI ì„œë²„ ì£¼ì†Œ

def execute_action(action: Dict):
    """Execute AI generated action"""

    # Step 1: action í˜•ì‹ í™•ì¸
    if action.get("type") != "device_control":
        print("â— Unknown action type:", action)
        return

    device_id = action.get("device_id")
    operation = action.get("operation")   # "on" / "off" / "toggle"

    if device_id is None:
        print("â— device_id not provided in action")
        return

    # Step 2: í˜„ì¬ ê¸°ê¸° ìƒíƒœ ë¶ˆëŸ¬ì˜¤ê¸° (DB ê¸°ì¤€ìœ¼ë¡œ ë³´ê³  ì‹¶ìœ¼ë©´ ì—¬ê¸°ë„ /devices-db ë¡œ ë°”ê¿€ ìˆ˜ ìˆìŒ)
    try:
        devices = requests.get(f"{BACKEND_URL}/devices-db").json()
    except Exception as e:
        print("â— Could not load devices:", e)
        return

    dev_map = {d["id"]: d for d in devices}

    if device_id not in dev_map:
        print("â— Device not found:", device_id)
        return

    current = dev_map[device_id]
    current_status = current["status"]

    # Step 3: ë‹¤ìŒ ìƒíƒœ ê²°ì •
    if operation == "toggle":
        if current["type"] == "door":
            next_status = "unlocked" if current_status == "locked" else "locked"
        else:
            next_status = "off" if current_status == "on" else "on"
    else:
        next_status = operation   # on/off/locked/unlocked

    # Step 4: ì„œë²„ì— ìƒíƒœ ì—…ë°ì´íŠ¸ ìš”ì²­ ğŸ‘‰ âœ… ì—¬ê¸°ë§Œ í•µì‹¬ ë³€ê²½
    try:
        res = requests.post(
            f"{BACKEND_URL}/devices-db/{device_id}",   # âœ… DBìš© ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³€ê²½
            json={"status": next_status},
            timeout=3,
        )
        if res.status_code == 200:
            print(f"âœ… Device updated (DB): id={device_id}, status={next_status}")
        else:
            print("â— Update failed:", res.text)
    except Exception as e:
        print("â— Error updating device:", e)


def tts_speak(text: str):
    """Convert text to speech and play"""
    try:
        import pyttsx3
        engine = pyttsx3.init()
        
        # Force English voice selection
        voices = engine.getProperty('voices')
        
        # Select best English voice
        english_voice_found = False
        for voice in voices:
            if any(lang in voice.id.lower() for lang in ['en_us', 'en-us', 'english', 'alex', 'daniel', 'karen', 'samantha']):
                engine.setProperty('voice', voice.id)
                english_voice_found = True
                print(f"ğŸ¤ Using English voice: {voice.name}")
                break
        
        if not english_voice_found and voices:
            # Use first voice (usually English on most systems)
            engine.setProperty('voice', voices[0].id)
            print(f"ğŸ¤ Using default voice: {voices[0].name}")
        
        # Voice settings
        engine.setProperty('rate', 160)     # Speaking rate
        engine.setProperty('volume', 0.9)   # Volume
        
        # Voice output
        print(f"ğŸ¤ TTS (ğŸ‡ºğŸ‡¸ EN): '{text}'")
        engine.say(text)
        engine.runAndWait()
        
    except Exception as e:
        print(f"âŒ TTS error: {e}")
        print("ğŸ’¬ Text response: " + text)


def start_ai_session_with_components(user: str, audio_processor, voice_recorder):
    """Start AI session with pre-initialized components"""
    print(f"[DEBUG] Starting AI session with existing components for user: {user}")
    
    try:
        # Initialize Gemini AI
        print("[DEBUG] Initializing Gemini AI...")
        gemini = GeminiAI(api_key=os.getenv("GEMINI_API_KEY"))
        print("[DEBUG] Gemini AI initialized")
        
        # Initialize permission manager
        print("[DEBUG] Initializing permission manager...")
        permission_manager = PermissionManager()
        print("[DEBUG] Permission manager initialized")
        
        # Add personalized greeting with TTS
        greeting = f"Hello {user}, what can I help you with today?"
        print(f"ğŸ¤– {greeting}")
        tts_speak(greeting)
        
        # Enter command mode
        print(f"\nğŸ¯ {user}'s AI Assistant Mode")
        command_mode(user, voice_recorder, audio_processor, gemini, permission_manager)
    except Exception as e:
        print(f"[ERROR] Exception in start_ai_session_with_components: {e}")
        import traceback
        traceback.print_exc()


def start_ai_session_with_existing_components(user: str, audio_processor=None, voice_recorder=None):
    """Start AI session for authenticated user with existing components"""
    print(f"[DEBUG] start_ai_session_with_existing_components called for user: {user}")
    
    try:
        # Initialize Gemini AI
        print("[DEBUG] Initializing Gemini AI...")
        api_key = os.getenv("GEMINI_API_KEY")
        print(f"[DEBUG] API Key exists: {api_key is not None}")
        gemini = GeminiAI(api_key=api_key)
        print("[DEBUG] Gemini AI initialized")
        
        # Initialize permission manager
        print("[DEBUG] Initializing permission manager...")
        permission_manager = PermissionManager()
        print("[DEBUG] Permission manager initialized")
        
        # Use existing audio components or create new ones
        if audio_processor is None or voice_recorder is None:
            print("[DEBUG] Creating new audio components...")
            audio_processor = AudioToText()
            voice_recorder = VoiceRecorder()
            print("[DEBUG] Audio components created")
        else:
            print("[DEBUG] Using existing audio components")
        
        # Add personalized greeting with TTS
        greeting = f"Hello {user}, what can I help you with today?"
        print(f"ğŸ¤– {greeting}")
        print("[DEBUG] About to call tts_speak...")
        tts_speak(greeting)
        print("[DEBUG] TTS completed")
        
        # Enter command mode
        print(f"\nğŸ¯ {user}'s AI Assistant Mode")
        print("[DEBUG] Entering command_mode...")
        command_mode(user, voice_recorder, audio_processor, gemini, permission_manager)
    except Exception as e:
        print(f"[ERROR] Exception in start_ai_session: {e}")
        import traceback
        traceback.print_exc()


def start_ai_session(user: str):
    """Start AI session for authenticated user"""
    print(f"[DEBUG] start_ai_session called for user: {user}")
    
    try:
        # Initialize Gemini AI
        print("[DEBUG] Initializing Gemini AI...")
        api_key = os.getenv("GEMINI_API_KEY")
        print(f"[DEBUG] API Key exists: {api_key is not None}")
        gemini = GeminiAI(api_key=api_key)
        print("[DEBUG] Gemini AI initialized")
        
        # Initialize permission manager
        print("[DEBUG] Initializing permission manager...")
        permission_manager = PermissionManager()
        print("[DEBUG] Permission manager initialized")
        
        # Initialize VoiceRecorder only (AudioToText causes issues)
        print("[DEBUG] Initializing voice recorder...")
        voice_recorder = VoiceRecorder()
        print("[DEBUG] Voice recorder initialized")
        
        # Skip AudioToText initialization for now
        audio_processor = None
        print("[DEBUG] Skipping AudioToText initialization to avoid conflicts")
        
        # Add personalized greeting with TTS
        greeting = f"Hello {user}, what can I help you with today?"
        print(f"ğŸ¤– {greeting}")
        print("[DEBUG] About to call tts_speak...")
        tts_speak(greeting)
        print("[DEBUG] TTS completed")
        
        # Enter command mode
        print(f"\nğŸ¯ {user}'s AI Assistant Mode")
        print("[DEBUG] Entering command_mode...")
        command_mode(user, voice_recorder, audio_processor, gemini, permission_manager)
    except Exception as e:
        print(f"[ERROR] Exception in start_ai_session: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
