import sounddevice as sd
import wavio
import numpy as np
import webrtcvad
import time

class VoiceRecorder:

    def __init__(self, sample_rate=16000, vad_aggressiveness=2):
        """
        ì´ˆê¸°í™”
        vad_aggressiveness: 0-3 (0ì´ ê°€ì¥ ë¯¼ê°, 3ì´ ê°€ì¥ ë‘”ê°)
        """
        self.sample_rate = sample_rate
        self.vad = webrtcvad.Vad(vad_aggressiveness)
        
    def record(self, filename="voice_sample.wav", duration=3):
        """ê¸°ì¡´ ë‹¨ìˆœ ë…¹ìŒ ë°©ì‹ (ê³ ì • ì‹œê°„)"""
        samplerate = 16000
        print("ğŸ™ï¸ Speak nowâ€¦")
        audio = sd.rec(int(duration * samplerate),
                       samplerate=samplerate,
                       channels=1,
                       dtype='int16')
        sd.wait()
        wavio.write(filename, audio, samplerate, sampwidth=2)
        print(f"âœ… Saved {filename}")
        return filename
    
    def record_with_vad(self, filename="voice_sample.wav", min_duration=1.0, max_duration=10.0, 
                        silence_duration=1.5, pre_recording_buffer=0.5):
        """
        VADë¥¼ ì‚¬ìš©í•œ ìŠ¤ë§ˆíŠ¸ ë…¹ìŒ
        min_duration: ìµœì†Œ ë…¹ìŒ ì‹œê°„ (ì´ˆ)
        max_duration: ìµœëŒ€ ë…¹ìŒ ì‹œê°„ (ì´ˆ)
        silence_duration: ì¹¨ë¬µìœ¼ë¡œ ê°„ì£¼í•  ì‹œê°„ (ì´ˆ)
        pre_recording_buffer: ìŒì„± ì‹œì‘ ì „ ë²„í¼ ì‹œê°„ (ì´ˆ)
        """
        print("ğŸ™ï¸ ë§ì”€í•´ì£¼ì„¸ìš”... (ìŒì„±ì„ ê°ì§€í•˜ë©´ ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤) / Please speak... (Recording starts when voice is detected)")
        
        frame_duration = 30  # ë°€ë¦¬ì´ˆ
        frame_size = int(self.sample_rate * frame_duration / 1000)
        
        # ì „ì²´ ì˜¤ë””ì˜¤ ì €ì¥ìš©
        audio_frames = []
        
        # ìŒì„± ê°ì§€ ë³€ìˆ˜
        speech_detected = False
        speech_started = False
        silence_start_time = None
        recording_start_time = time.time()
        
        # ì‚¬ì „ ë…¹ìŒ ë²„í¼
        pre_buffer_frames = []
        pre_buffer_size = int(pre_recording_buffer * 1000 / frame_duration)
        
        with sd.InputStream(samplerate=self.sample_rate, channels=1, dtype='int16',
                          blocksize=frame_size) as stream:
            
            while True:
                current_time = time.time()
                elapsed_time = current_time - recording_start_time
                
                # ìµœëŒ€ ë…¹ìŒ ì‹œê°„ ì²´í¬
                if elapsed_time > max_duration:
                    print("â±ï¸ ìµœëŒ€ ë…¹ìŒ ì‹œê°„ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. / Maximum recording time reached.")
                    break
                
                # ì˜¤ë””ì˜¤ í”„ë ˆì„ ì½ê¸°
                audio_chunk, _ = stream.read(frame_size)
                audio_chunk = audio_chunk.flatten()
                
                # VADë¡œ ìŒì„± ê°ì§€
                is_speech = self.vad.is_speech(audio_chunk.tobytes(), self.sample_rate)
                
                # ì‚¬ì „ ë²„í¼ ê´€ë¦¬
                if not speech_started:
                    pre_buffer_frames.append(audio_chunk)
                    if len(pre_buffer_frames) > pre_buffer_size:
                        pre_buffer_frames.pop(0)
                
                if is_speech:
                    if not speech_started:
                        speech_started = True
                        print("ğŸ”´ ë…¹ìŒ ì‹œì‘! / Recording started!")
                        # ì‚¬ì „ ë²„í¼ì˜ í”„ë ˆì„ë“¤ì„ ë¨¼ì € ì¶”ê°€
                        audio_frames.extend(pre_buffer_frames)
                    
                    speech_detected = True
                    silence_start_time = None
                    audio_frames.append(audio_chunk)
                    
                else:
                    if speech_started:
                        audio_frames.append(audio_chunk)
                        
                        if silence_start_time is None:
                            silence_start_time = current_time
                        elif current_time - silence_start_time > silence_duration:
                            # ì¶©ë¶„í•œ ì¹¨ë¬µì´ ê°ì§€ë˜ë©´ ë…¹ìŒ ì¢…ë£Œ
                            if len(audio_frames) * frame_duration / 1000 >= min_duration:
                                print("ğŸ”‡ ìŒì„± ì¢…ë£Œ ê°ì§€ / End of speech detected")
                                break
                
                # ìŒì„±ì´ ì‹œì‘ë˜ì—ˆê³  ìµœì†Œ ì‹œê°„ì´ ì§€ë‚¬ëŠ”ì§€ ì²´í¬
                if speech_started and elapsed_time > min_duration + pre_recording_buffer:
                    # ìƒíƒœ í‘œì‹œ (ì„ íƒì‚¬í•­)
                    pass
        
        if not speech_detected:
            print("âš ï¸ ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. / No voice detected. Please try again.")
            return None
        
        # ì˜¤ë””ì˜¤ ì €ì¥
        if audio_frames:
            audio_data = np.concatenate(audio_frames)
            wavio.write(filename, audio_data, self.sample_rate, sampwidth=2)
            print(f"âœ… ì €ì¥ ì™„ë£Œ / Saved: {filename}")
            return filename
        else:
            print("âš ï¸ ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤. / No audio recorded.")
            return None

# ê¸°ë³¸ record ë©”ì„œë“œë¥¼ VAD ë²„ì „ìœ¼ë¡œ êµì²´
VoiceRecorder.record_original = VoiceRecorder.record
VoiceRecorder.record = lambda self, filename="voice_sample.wav": self.record_with_vad(filename)

'''    
if __name__ == "__main__":
    VoiceRecorder().record()
'''