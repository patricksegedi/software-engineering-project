// src/pages/User/Profile.jsx
import { useState } from "react"
import { useAuth } from "../../AuthContext"
import "./Profile.css"

const VOICES = ["Luna", "Mira", "Oscar"]

const TRAINING_SENTENCES = [
  "Hi, this is my personal smart speaker.",
  "Turn on the living room lights, please.",
  "Good night, lock the main door.",
]

// ë°ëª¨ìš© ìœ ì € ì •ë³´ (Auth ì—°ë™ ì „)
const demoUser = {
  email: "user@example.com",
  role: "User",
  familyRole: "Father",
}

// ===== WAV ì¸ì½”ë”©ìš© í—¬í¼ í•¨ìˆ˜ & ì „ì—­ ë³€ìˆ˜ë“¤ =====

// ë…¹ìŒ ë²„í¼ë“¤ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
function mergeBuffers(channelBuffer, recordingLength) {
  const result = new Float32Array(recordingLength)
  let offset = 0
  for (let i = 0; i < channelBuffer.length; i++) {
    result.set(channelBuffer[i], offset)
    offset += channelBuffer[i].length
  }
  return result
}

// Float32Array PCM ë°ì´í„°ë¥¼ WAV í¬ë§· Blobìœ¼ë¡œ ë³€í™˜
function encodeWAV(samples, sampleRate) {
  const buffer = new ArrayBuffer(44 + samples.length * 2)
  const view = new DataView(buffer)

  function writeString(offset, string) {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i))
    }
  }

  // RIFF í—¤ë”
  writeString(0, "RIFF")
  view.setUint32(4, 36 + samples.length * 2, true)
  writeString(8, "WAVE")
  writeString(12, "fmt ")
  view.setUint32(16, 16, true) // fmt chunk size
  view.setUint16(20, 1, true) // audio format (1 = PCM)
  view.setUint16(22, 1, true) // num channels
  view.setUint32(24, sampleRate, true) // sample rate
  view.setUint32(28, sampleRate * 2, true) // byte rate
  view.setUint16(32, 2, true) // block align
  view.setUint16(34, 16, true) // bits per sample
  writeString(36, "data")
  view.setUint32(40, samples.length * 2, true)

  // ì‹¤ì œ PCM ë°ì´í„°(16bit LE)
  let offset = 44
  for (let i = 0; i < samples.length; i++, offset += 2) {
    const s = Math.max(-1, Math.min(1, samples[i]))
    view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true)
  }

  return new Blob([view], { type: "audio/wav" })
}

// ì˜¤ë””ì˜¤ ë…¹ìŒì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ë“¤ (ì»´í¬ë„ŒíŠ¸ ë°–ì— ë‘¬ì„œ ë Œë” ì‚¬ì´ì—ì„œë„ ìœ ì§€)
let audioContext = null
let processor = null
let inputNode = null
let stream = null
let leftChannel = []
let recordingLength = 0
let sampleRate = 44100
// ===============================================

export default function Profile() {
  const { user } = useAuth()

  // Assistant voice ì„ íƒìš© state
  const [selectedVoice, setSelectedVoice] = useState("Luna")

  // ğŸ”‰ ìŒì„± í•™ìŠµìš© state
  const [isRecording, setIsRecording] = useState(false)
  const [trainingStatus, setTrainingStatus] = useState("Not started")

  // 1) ì„œë²„ë¡œ WAV íŒŒì¼ ì—…ë¡œë“œ
  const uploadRecording = async (blob) => {
    try {
      // ìŠ¤í”¼ì»¤ ìª½ username = ì´ë©”ì¼ ì•ë¶€ë¶„ (íšŒì›ê°€ì… ë•Œ ë³´ë‚¸ ê²ƒê³¼ ë™ì¼)
      const email = user?.email || demoUser.email
      const username = email.split("@")[0]

      const fd = new FormData()
      fd.append("file", blob, "voice.wav") // ğŸ”¥ ì—¬ê¸°ì„œ í™•ì¥ìë¥¼ wavë¡œ ì‚¬ìš©

      const res = await fetch(`http://127.0.0.1:8000/users/${username}/voice`, {
        method: "POST",
        body: fd,
      })

      if (!res.ok) {
        const txt = await res.text()
        throw new Error(txt)
      }

      setTrainingStatus("Completed")
      alert("ë…¹ìŒí•œ WAV ìŒì„±ì´ ìŠ¤í”¼ì»¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    } catch (err) {
      console.error(err)
      setTrainingStatus("Failed")
      alert("ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: " + err.message)
    } finally {
      setIsRecording(false)
    }
  }

  // 2) ë…¹ìŒ ì‹œì‘/ì¢…ë£Œ í† ê¸€ (AudioContext ì‚¬ìš©, WAVë¡œ ë³€í™˜)
  const startOrStopTraining = async () => {
    // ì´ë¯¸ ë…¹ìŒ ì¤‘ì´ë©´ â†’ ì¢…ë£Œ + WAV ìƒì„± + ì—…ë¡œë“œ
    if (isRecording) {
      if (processor) processor.disconnect()
      if (inputNode) inputNode.disconnect()
      if (audioContext) await audioContext.close()
      if (stream) stream.getTracks().forEach((t) => t.stop())

      // ë²„í¼ í•©ì¹˜ê³  WAVë¡œ ì¸ì½”ë”©
      const samples = mergeBuffers(leftChannel, recordingLength)
      const wavBlob = encodeWAV(samples, sampleRate)

      // ë‹¤ìŒ ë…¹ìŒì„ ìœ„í•´ ì´ˆê¸°í™”
      leftChannel = []
      recordingLength = 0

      // ì„œë²„ë¡œ ì—…ë¡œë“œ
      await uploadRecording(wavBlob)
      return
    }

    // ë…¹ìŒ ì‹œì‘
    try {
      stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      audioContext = new (window.AudioContext || window.webkitAudioContext)()
      sampleRate = audioContext.sampleRate

      inputNode = audioContext.createMediaStreamSource(stream)
      processor = audioContext.createScriptProcessor(4096, 1, 1)

      processor.onaudioprocess = (e) => {
        const inputData = e.inputBuffer.getChannelData(0)
        leftChannel.push(new Float32Array(inputData))
        recordingLength += inputData.length
      }

      inputNode.connect(processor)
      processor.connect(audioContext.destination)

      setIsRecording(true)
      setTrainingStatus("Recordingâ€¦")
    } catch (err) {
      console.error(err)
      alert("ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    }
  }

  return (
    <div className="profile-container">
      <h1 className="profile-title">My profile</h1>
      <p className="profile-subtitle">
        Manage your account, family role and voice preferences.
      </p>

      <div className="profile-grid">
        {/* User info card */}
        <section className="profile-card">
          <h2 className="profile-card-title">Account</h2>
          <p className="profile-field">
            <span> Email </span>
            <strong>{demoUser.email}</strong>
          </p>
          <p className="profile-field">
            <span> Role </span>
            <strong>{demoUser.role}</strong>
          </p>
          <p className="profile-field">
            <span> Family role </span>
            <strong>{demoUser.familyRole}</strong>
          </p>
          <p className="profile-hint">
            (In a real system, this would come from your account settings.)
          </p>
        </section>

        {/* Voice profile card */}
        <section className="profile-card">
          <h2 className="profile-card-title">Assistant voice</h2>
          <p className="profile-text">
            Choose how your smart speaker sounds. This is your personal voice
            profile.
          </p>

          <div className="voice-select-row">
            {VOICES.map((voice) => (
              <button
                key={voice}
                type="button"
                className={`voice-pill ${
                  selectedVoice === voice ? "voice-pill-selected" : ""
                }`}
                onClick={() => setSelectedVoice(voice)}
              >
                {voice}
              </button>
            ))}
          </div>

          <p className="selected-voice-text">
            Current voice: <strong>{selectedVoice}</strong>
          </p>

          <button
            type="button"
            className="primary-btn"
            onClick={() => alert("Demo only â€“ no backend connected")}
          >
            Save changes
          </button>
        </section>
      </div>

      {/* Voice training section */}
      <section className="profile-section">
        <h2>Train your voice</h2>
        <p>
          Teach the speaker how you sound. This will record a short sample of
          your voice and save it to the smart speaker.
        </p>

        <p>
          Training status: <strong>{trainingStatus}</strong>
        </p>

        <button
          type="button"
          className="primary-btn"
          onClick={startOrStopTraining}
        >
          {isRecording ? "Stop & upload" : "Start training"}
        </button>

        <p style={{ fontSize: 12, marginTop: 8, color: "#666" }}>
          {isRecording
            ? "ì§€ê¸ˆ ë§í•˜ì„¸ìš”... ë‹¤ì‹œ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë…¹ìŒì´ ì¢…ë£Œë˜ê³  ì—…ë¡œë“œë©ë‹ˆë‹¤."
            : "ë²„íŠ¼ì„ ëˆ„ë¥¸ ë’¤ 2â€“3ì´ˆ ì •ë„ í‰ì†Œì²˜ëŸ¼ ë§í•´ ì£¼ì„¸ìš”."}
        </p>
      </section>
    </div>
  )
}
