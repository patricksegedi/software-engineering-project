from speechbrain.pretrained import EncoderClassifier

import soundfile as sf
import torch
import numpy as np
import os
import time
from scipy.spatial.distance import euclidean
try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    from sklearn.metrics import roc_curve, auc
    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False
    print("ğŸ“Š ì‹œê°í™” íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶„ì„ë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤ / Visualization packages not available. Running basic analysis only.")

class SpeakerVerifier:

    def __init__(self, threshold=0.4, detailed_analysis=True):
        self.model = EncoderClassifier.from_hparams("speechbrain/spkrec-ecapa-voxceleb")
        self.threshold = threshold
        self.detailed_analysis = detailed_analysis
        self.analysis_history = []  # ë¶„ì„ ê¸°ë¡ ì €ì¥

    def get_voice_print(self, path):
        """ìŒì„± íŒŒì¼ì—ì„œ íŠ¹ì§• ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ê³  ìƒì„¸ ì •ë³´ ë¶„ì„"""
        start_time = time.time()
        
        data, sample_rate = sf.read(path, dtype="float32", always_2d=True)
        data = data.mean(axis=1)  # stereo -> mono
        
        # ìŒì„± í’ˆì§ˆ ë¶„ì„
        audio_length = len(data) / sample_rate
        audio_power = np.mean(data ** 2)
        audio_snr = 10 * np.log10(audio_power / (np.var(data) + 1e-10))
        
        waveform = torch.from_numpy(data).unsqueeze(0)  # NumPy-array -> PyTorch-tensor
        voice_print = self.model.encode_batch(waveform)
        embedding = voice_print.squeeze().detach().cpu().numpy()
        
        extraction_time = time.time() - start_time
        
        if self.detailed_analysis:
            print(f"    ğŸ“Š ìŒì„± ë¶„ì„ / Audio Analysis:")
            print(f"      - ê¸¸ì´ / Length: {audio_length:.2f}s")
            print(f"      - ìƒ˜í”Œë ˆì´íŠ¸ / Sample Rate: {sample_rate}Hz")
            print(f"      - ì‹ í˜¸ í’ˆì§ˆ / Signal Quality: {audio_snr:.2f}dB")
            print(f"      - íŠ¹ì§• ë²¡í„° ì°¨ì› / Embedding Dimensions: {embedding.shape[0]}")
            print(f"      - íŠ¹ì§• ì¶”ì¶œ ì‹œê°„ / Extraction Time: {extraction_time:.3f}s")
            print(f"      - ë²¡í„° í¬ê¸° / Vector Magnitude: {np.linalg.norm(embedding):.3f}")
        
        return embedding

    def score_sample(self, sample_file, test_file):
        """ë‘ ìŒì„± íŒŒì¼ì˜ ìœ ì‚¬ë„ë¥¼ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ê³„ì‚°"""
        recorded_print = self.get_voice_print(test_file)
        sample_print = self.get_voice_print(sample_file)
        
        # 1. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ê¸°ë³¸)
        cosine_similarity = np.dot(recorded_print, sample_print) / (
            np.linalg.norm(recorded_print) * np.linalg.norm(sample_print)
        )
        
        # 2. ìœ í´ë¦¬ë“œ ê±°ë¦¬ (ì •ê·œí™”)
        euclidean_dist = euclidean(recorded_print, sample_print)
        euclidean_similarity = 1 / (1 + euclidean_dist)
        
        # 3. ë§¨í•˜íƒ„ ê±°ë¦¬ (ì •ê·œí™”) - ì§ì ‘ ê³„ì‚°
        manhattan_dist = np.sum(np.abs(recorded_print - sample_print))
        manhattan_similarity = 1 / (1 + manhattan_dist)
        
        if self.detailed_analysis:
            print(f"    ğŸ“ ìœ ì‚¬ë„ ë¶„ì„ / Similarity Analysis:")
            print(f"      - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ / Cosine Similarity: {cosine_similarity:.4f}")
            print(f"      - ìœ í´ë¦¬ë“œ ìœ ì‚¬ë„ / Euclidean Similarity: {euclidean_similarity:.4f}")
            print(f"      - ë§¨í•˜íƒ„ ìœ ì‚¬ë„ / Manhattan Similarity: {manhattan_similarity:.4f}")
            print(f"      - ë²¡í„° ì°¨ì´ í¬ê¸° / Vector Difference Magnitude: {euclidean_dist:.3f}")
        
        # ë¶„ì„ ê¸°ë¡ ì €ì¥
        self.analysis_history.append({
            'sample_file': sample_file,
            'cosine_similarity': cosine_similarity,
            'euclidean_similarity': euclidean_similarity,
            'manhattan_similarity': manhattan_similarity,
            'euclidean_distance': euclidean_dist
        })
        
        return cosine_similarity  # ê¸°ë³¸ì ìœ¼ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë°˜í™˜
    
    def verify(self, recorded_file, folder_path):
        best_score = float('-inf')
        #best_match = None
        for filename in os.listdir(folder_path):
            if filename.lower().endswith(".wav"):
                sample_file = os.path.join(folder_path, filename)
                score = self.score_sample(sample_file, recorded_file)

                print(f"{filename}: {score:.3f}") #for debugging purposes

                if score > best_score:
                    best_score = score
                    #best_match = filename

        return best_score >= self.threshold
    
    def analyze_threshold_performance(self, voice_samples_dir="voice_samples"):
        """ì„ê³„ê°’ ì„±ëŠ¥ ë¶„ì„ ë° ìµœì í™”"""
        print("\nğŸ”¬ ì„ê³„ê°’ ì„±ëŠ¥ ë¶„ì„ / Threshold Performance Analysis")
        print("=" * 60)
        
        thresholds = np.arange(0.1, 0.9, 0.05)
        accuracies = []
        
        for threshold in thresholds:
            self.threshold = threshold
            correct = 0
            total = 0
            
            # ê° ì‚¬ìš©ìì˜ ìŒì„± íŒŒì¼ë“¤ë¡œ í…ŒìŠ¤íŠ¸
            for user_folder in os.listdir(voice_samples_dir):
                user_path = os.path.join(voice_samples_dir, user_folder)
                if not os.path.isdir(user_path):
                    continue
                    
                files = [f for f in os.listdir(user_path) if f.endswith('.wav')]
                for i, test_file in enumerate(files):
                    test_path = os.path.join(user_path, test_file)
                    identified_user, score = self.identify_speaker(test_path, voice_samples_dir)
                    
                    if identified_user == user_folder:
                        correct += 1
                    total += 1
            
            accuracy = correct / total if total > 0 else 0
            accuracies.append(accuracy)
            print(f"ì„ê³„ê°’ / Threshold {threshold:.2f}: ì •í™•ë„ / Accuracy {accuracy:.3f}")
        
        # ìµœì  ì„ê³„ê°’ ì°¾ê¸°
        best_threshold = thresholds[np.argmax(accuracies)]
        best_accuracy = max(accuracies)
        
        print(f"\nğŸ¯ ìµœì  ì„ê³„ê°’ / Optimal Threshold: {best_threshold:.2f}")
        print(f"ğŸ¯ ìµœê³  ì •í™•ë„ / Best Accuracy: {best_accuracy:.3f}")
        
        self.threshold = best_threshold
        return best_threshold, best_accuracy
    
    def generate_analysis_report(self):
        """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.analysis_history:
            print("ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤ / No analysis history")
            return
            
        print("\nğŸ“Š ë¶„ì„ ë¦¬í¬íŠ¸ / Analysis Report")
        print("=" * 50)
        
        cosine_scores = [h['cosine_similarity'] for h in self.analysis_history]
        euclidean_scores = [h['euclidean_similarity'] for h in self.analysis_history]
        
        print(f"ì´ ë¹„êµ íšŸìˆ˜ / Total Comparisons: {len(self.analysis_history)}")
        print(f"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í‰ê·  / Avg Cosine Similarity: {np.mean(cosine_scores):.4f}")
        print(f"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í‘œì¤€í¸ì°¨ / Std Cosine Similarity: {np.std(cosine_scores):.4f}")
        print(f"ìœ í´ë¦¬ë“œ ìœ ì‚¬ë„ í‰ê·  / Avg Euclidean Similarity: {np.mean(euclidean_scores):.4f}")
        
        # ì„ê³„ê°’ë³´ë‹¤ ë†’ì€ ì ìˆ˜ì˜ ë¹„ìœ¨
        above_threshold = sum(1 for s in cosine_scores if s >= self.threshold)
        print(f"ì„ê³„ê°’ ì´ìƒ ë¹„ìœ¨ / Above Threshold Ratio: {above_threshold}/{len(cosine_scores)} ({above_threshold/len(cosine_scores)*100:.1f}%)")
    
    def save_analysis_data(self, filename="speaker_analysis.csv"):
        """ë¶„ì„ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥"""
        if not self.analysis_history:
            return
            
        try:
            import pandas as pd
            df = pd.DataFrame(self.analysis_history)
            df.to_csv(filename, index=False)
            print(f"ğŸ“ ë¶„ì„ ë°ì´í„° ì €ì¥ / Analysis data saved: {filename}")
        except ImportError:
            print("ğŸ“ pandasê°€ ì—†ì–´ì„œ CSV ì €ì¥ì„ ìƒëµí•©ë‹ˆë‹¤ / Skipping CSV save (pandas not available)")
    
    def identify_speaker(self, recorded_file, voice_samples_dir="voice_samples"):
        """ëª¨ë“  ë“±ë¡ëœ ì‚¬ìš©ì ì¤‘ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ í™”ìë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
        best_score = float('-inf')
        best_user = None
        
        # voice_samples ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ì‚¬ìš©ì í´ë” í™•ì¸
        if not os.path.exists(voice_samples_dir):
            print(f"ìŒì„± ìƒ˜í”Œ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤ / Voice samples directory not found: {voice_samples_dir}")
            return None, 0.0
            
        for user_folder in os.listdir(voice_samples_dir):
            user_path = os.path.join(voice_samples_dir, user_folder)
            
            # ë””ë ‰í† ë¦¬ì¸ì§€ í™•ì¸
            if not os.path.isdir(user_path):
                continue
                
            print(f"\n=== {user_folder} ì‚¬ìš©ìì™€ ë¹„êµ ì¤‘ / Comparing with {user_folder} ===")
            
            # í•´ë‹¹ ì‚¬ìš©ìì˜ ëª¨ë“  ìŒì„± ìƒ˜í”Œê³¼ ë¹„êµ
            user_best_score = float('-inf')
            for filename in os.listdir(user_path):
                if filename.lower().endswith(".wav"):
                    sample_file = os.path.join(user_path, filename)
                    score = self.score_sample(sample_file, recorded_file)
                    
                    print(f"  {filename}: {score:.3f}")
                    
                    if score > user_best_score:
                        user_best_score = score
            
            print(f"{user_folder} ìµœê³  ì ìˆ˜ / Best score: {user_best_score:.3f}")
            
            # ì „ì²´ ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸
            if user_best_score > best_score:
                best_score = user_best_score
                best_user = user_folder
        
        print(f"\n>>> ìµœì¢… ê²°ê³¼ / Final result: {best_user} ({best_score:.3f})")
        
        # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ì—ë§Œ ì‚¬ìš©ì ë°˜í™˜
        if best_score >= self.threshold:
            return best_user, best_score
        else:
            return None, best_score
    
